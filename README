Name:
UWNetID:

Name: Tye Coleman
UWNetID: tcolem

Name: Bianca Greydinger
UWNetID: bgreyd

Instructions to reproduce the results:
  Download our `bufferbloat.py`, `run.sh`, and `run_bbr.sh` into the existing file structure. Then run `sudo ./run.sh` to generate tcp reno graphs and run `sudo ./run_bbr.sh` to generate bbr graphs.

Answers to the questions:
Part 2
  1. q=20 :  avg 0.349251922222
             std 0.5080346978384717
     q=100 : avg 0.7046730897435898
             std 0.84929256936187
             
  2. The difference in webpage fetch times with different-sized queues is caused by bufferbloat. Bufferbloat is a condition where excess buffering of packets cause higher latency and delay variations. 
     As you can see the larger queue has a longer average fetch time and higher variation for the values. When the queue size is larger, each packet will have to wait longer in the buffer before it can be transmitted, 
     which leads to high latency.
     
  3. TODO
  
  4. RTT is proportional to the queue size. As described in question 2, larger queue size results in longer delay for the packets to be transmitted, meaning larger RTT.
  
  5. One way to mitigate this problem is to reduce or set a maximum size on the queue such that is it the most efficient queue size for the particular transmission rate.
     Another way to solve this issue is to use an active queue management algorithm (AQM). This algorithm dynamically controls the amount of packets entering the network.
     It monitors the queue length and drop packets when the queue gets too long, and tells the sender to reduce the transmission rate to maintain efficiency.
     
Part 3
  1. q=20 :  avg 0.12396319191919
             std 0.0259405164694256
     q=100 : avg 0.12376845454545 
             std 0.024401307801627192
             
  2. The average fetch time between the two queue sizes are very similar as well as the standard deviation for both queues. Suprisingly, the longer queue length (q=100) gave a slightly lower average fetch time for our results.
     On the other hand in Part2, the average fetch time for q=100 was significantly higher than the fetch time for q=20. 
     
  3. TODO
  4. TODO
